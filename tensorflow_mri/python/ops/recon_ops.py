# Copyright 2021 University College London. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""Image reconstruction operations.

This module contains functions for MR image reconstruction.
"""

import tensorflow as tf
import tensorflow_nufft as tfft

from tensorflow_mri.python.ops import coil_ops
from tensorflow_mri.python.ops import fft_ops
from tensorflow_mri.python.ops import linalg_ops
from tensorflow_mri.python.ops import traj_ops
from tensorflow_mri.python.utils import check_utils
from tensorflow_mri.python.utils import tensor_utils


def reconstruct(kspace,
                trajectory=None,
                density=None,
                sensitivities=None,
                method=None,
                **kwargs):
  """MR image reconstruction gateway.

  Reconstructs an image given the corresponding *k*-space measurements.

  This is a gateway function to different image reconstruction methods. The
  reconstruction method can be selected with the `method` argument. If the
  `method` argument is not specified, a method is automatically selected based
  on the input arguments.

  Supported methods are:

  * **fft**: Simple fast Fourier transform (FFT) reconstruction for Cartesian
    *k*-space data. This is the default method if only a `kspace` argument is
    given.
  * **nufft**: Non-uniform fast Fourier transform (NUFFT) reconstruction for
    non-Cartesian *k*-space data. This is the default method if `kspace`,
    `trajectory` and (optionally) `density` are given.
  * **sense**: SENSitivity Encoding (SENSE) [1]_ reconstruction for Cartesian
    *k*-space data. This is the default method if `kspace` and `sensitivities`
    are given.
  * **cg_sense**: Conjugate gradient SENSE (CG-SENSE) [2]_ reconstruction for
    non-Cartesian *k*-space data. This is the default method if `kspace`,
    `trajectory`, `sensitivities` and (optionally) `density` are given.

  .. note::
    This function supports CPU and GPU computation.

  .. note::
    This function supports batches of inputs, which are processed in parallel
    whenever possible.

  .. warning::
    In graph mode, some methods may fail if static shapes are unknown. Support
    for this is a work in progress. In the meantime, check out `tf.ensure_shape`
    to set the static shapes of the input arguments before calling this
    function.

  See also `tfmr.estimate_coil_sensitivities` and `tfmr.combine_coils`.

  Args:
    kspace: A `Tensor`. The *k*-space samples. Must have type `complex64` or
      `complex128`. `kspace` can be either Cartesian or non-Cartesian. A
      Cartesian `kspace` must have shape `[..., C, *K]`, where `K` is the shape
      of the spatial frequency dimensions, `C` is the number of coils and `...`
      is the batch shape, which can have any rank. Note that `K` should be the
      reduced or undersampled shape, i.e., no zero-filling of any kind should be
      included. A non-Cartesian `kspace` must have shape `[..., C, M]`, where
      `M` is the number of samples, `C` is the number of coils and `...` is the
      batch shape, which can have any rank.
    trajectory: A `Tensor`. The *k*-space trajectory. Must have type `float32`
      or `float64`. Must have shape `[..., M, N]`, where `N` is the number of
      spatial dimensions, `N` is the number of *k*-space samples and `...` is
      the batch shape, which can have any rank and must be broadcastable to the
      batch shape of `kspace`. `trajectory` is required when `method` is
      `"nufft"` or `"cg_sense"`. For other methods, this parameter is not
      relevant.
    density: A `Tensor`. The sampling density. Must have type `float32` or
      `float64`. Must have shape `[..., M]`, where `M` is the number of
      *k*-space samples and `...` is the batch shape, which can have any rank
      and must be broadcastable to the batch shape of `kspace`. `density` is
      optional when `method` is `"nufft"` or `"cg_sense"`. For other methods,
      this parameter is not relevant.
    sensitivities: A `Tensor`. The coil sensitivity maps. Must have type
      `complex64` or `complex128`. Must have shape `[..., C, *S]`, where `S` is
      shape of the spatial dimensions, `C` is the number of coils and `...` is
      the batch shape, which can have any rank and must be broadcastable to the
      batch shape of `kspace`. `sensitivities` is required when `method` is
      `"sense"` or `"cg_sense"`. For other methods, this parameter is not
      relevant.
    method: A `string`. The reconstruction method. Must be one of `"fft"`,
      `"nufft"`, `"sense"` or `"cg_sense"`.
    **kwargs: Additional method-specific keyword arguments. See Notes for the
      method-specific arguments.

  Notes:
    This function accepts several method dependent arguments:

    * For `method="fft"`, provide `kspace` and, optionally, `sensitivities`.
      If provided, `sensitivities` are used for adaptive coil combination (see
      `tfmr.combine_coils`). If not provided, multi-coil inputs are combined
      using the sum of squares method. In addition, the following keyword
      arguments are accepted:

      * **rank**: An optional `int`. The rank (in the sense of spatial
        dimensionality) of this operation. Defaults to `kspace.shape.rank` if
        `multicoil` is `False` and `kspace.shape.rank - 1` if `multicoil` is
        `True`.
      * **multicoil**: An optional `bool`. Whether the input *k*-space has a
        coil dimension. Defaults to `True` if `sensitivities` were specified,
        `False` otherwise.
      * **combine_coils**: An optional `bool`. If `True`, multi-coil images
        are combined. Otherwise, the uncombined images are returned. Defaults to
        `True`.

    * For `method="nufft"`, provide `kspace`, `trajectory` and, optionally,
      `density`. If `density` is not provided, an estimate will be used (see
      `tfmr.estimate_density`). In addition, the following keyword arguments
      are accepted:

      * **image_shape**: A `TensorShape` or list of `ints`. The shape of the
        output images. This parameter must be provided.
      * **multicoil**: An optional `bool`. Whether the input *k*-space has a
        coil dimension. Defaults to `True` if `sensitivities` were specified,
        `False` otherwise.
      * **combine_coils**: An optional `bool`. If `True`, multi-coil images
        are combined. Otherwise, the uncombined images are returned. Defaults to
        `True`.

    * For `method="sense"`, provide `kspace` and `sensitivities`. In addition,
      the following keyword arguments are accepted:

      * **reduction_axis**: An `int` or a list of `ints`. The reduced axes. This
        parameter must be provided.
      * **reduction_factor**: An `int` or a list of `ints`. The reduction
        factors corresponding to each reduction axis. The output image will have
        dimension `kspace.shape[ax] * r` for each pair `ax` and `r` in
        `reduction_axis` and `reduction_factor`. This parameter must be
        provided.
      * **rank**: An optional `int`. The rank (in the sense of spatial
        dimensionality) of this operation. Defaults to `kspace.shape.rank - 1`.
        Therefore, if `rank` is not specified, axis 0 is interpreted to be the
        coil axis and the remaining dimensions are interpreted to be spatial
        dimensions. You must specify `rank` if you intend to provide any batch
        dimensions in `kspace` and/or `sensitivities`.
      * **l2_regularizer**: An optional `float`. The L2 regularization factor
        used when solving the linear least-squares problem. Ignored if
        `fast=False`. Defaults to 0.0.
      * **fast**: An optional `bool`. Defaults to `True`. If `False`, use a
        numerically robust orthogonal decomposition method to solve the linear
        least-squares. This algorithm finds the solution even for rank deficient
        matrices, but is significantly slower. For more details, see
        `tf.linalg.lstsq`.

    * For `method="cg_sense"`, provide `kspace`, `trajectory`, `density`
      (optional) and `sensitivities`. If `density` is not provided, an estimate
      will be used (see `tfmr.estimate_density`). In addition, the following
      keyword arguments are accepted:

      * **tol**: An optional `float`. The convergence tolerance for the
        conjugate gradient iteration. Defaults to 1e-05.
      * **max_iter**: An optional `int`. The maximum number of iterations for
        the conjugate gradient iteration. Defaults to 10.
      * **return_cg_state**: An optional `bool`. Defaults to `False`. If `True`,
        return a tuple containing the image and an object describing the final
        state of the CG iteration. For more details about the CG state, see
        `tfmr.conjugate_gradient`. If `False`, only the image is returned.

  Returns:
    A `Tensor`. The reconstructed images. Has the same type as `kspace`. Has
    shape `[..., S]`, where `...` is the batch shape of `kspace` and `S` is the
    spatial shape.

  References:
    .. [1] Pruessmann, K.P., Weiger, M., Scheidegger, M.B. and Boesiger, P.
      (1999), SENSE: Sensitivity encoding for fast MRI. Magn. Reson. Med.,
      42: 952-962.
      https://doi.org/10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S

    .. [2] Pruessmann, K.P., Weiger, M., BÃ¶rnert, P. and Boesiger, P. (2001),
      Advances in sensitivity encoding with arbitrary k-space trajectories.
      Magn. Reson. Med., 46: 638-651. https://doi.org/10.1002/mrm.1241
  """
  method = _select_reconstruction_method(
    kspace, trajectory, density, sensitivities, method)

  args = {'trajectory': trajectory,
          'density': density,
          'sensitivities': sensitivities}

  args = {name: arg for name, arg in args.items() if arg is not None}

  return _MR_RECON_METHODS[method](kspace, **{**args, **kwargs})


def _fft(kspace,
         sensitivities=None,
         rank=None,
         multicoil=None,
         combine_coils=True):
  """MR image reconstruction using FFT.

  For the parameters, see `tfmr.reconstruct`.
  """
  kspace = tf.convert_to_tensor(kspace)
  if sensitivities is not None:
    sensitivities = tf.convert_to_tensor(sensitivities)
  # Check inputs and set defaults.
  if multicoil is None:
    # `multicoil` defaults to True if sensitivities were passed; False
    # otherwise.
    multicoil = sensitivities is not None
  if rank is None:
    # If `rank` not specified, assume no leading batch dimensions, so all dims
    # are spatial dims (minus coil dimension if `multicoil` is true).
    rank = kspace.shape.rank
    if multicoil:
      rank -= 1 # Account for coil dimension.
    if rank > 3:
      raise ValueError(
        f"Can only reconstruct images up to rank 3, but `kspace` has "
        f"{rank} spatial dimensions. If `kspace` has any leading batch "
        f"dimensions, please set the argument `rank` explicitly.")
  else:
    rank = check_utils.validate_type(rank, int, "rank")
    if rank > 3:
      raise ValueError(f"Argument `rank` must be <= 3, but got: {rank}")
  # Do FFT.
  axes = list(range(-rank, 0)) # pylint: disable=invalid-unary-operand-type
  image = fft_ops.ifftn(kspace, axes=axes, shift=True)
  # If multicoil, do coil combination. Will do adaptive combine if
  # `sensitivities` are given, otherwise sum of squares.
  if multicoil and combine_coils:
    image = coil_ops.combine_coils(image, maps=sensitivities, coil_axis=-rank-1) # pylint: disable=invalid-unary-operand-type
  return image


def _nufft(kspace,
           trajectory,
           density=None,
           sensitivities=None,
           image_shape=None,
           multicoil=None,
           combine_coils=True):
  """MR image reconstruction using NUFFT.

  For the parameters, see `tfmr.reconstruct`.
  """
  kspace = tf.convert_to_tensor(kspace)
  trajectory = tf.convert_to_tensor(trajectory)
  if density is not None:
    density = tf.convert_to_tensor(density)
  if sensitivities is not None:
    sensitivities = tf.convert_to_tensor(sensitivities)
  # Infer rank from number of dimensions in trajectory.
  rank = trajectory.shape[-1]
  if rank > 3:
    raise ValueError(
      f"Can only reconstruct images up to rank 3, but `trajectory` implies "
      f"rank {rank}.")
  # Check inputs and set defaults.
  if image_shape is None:
    # `image_shape` is required.
    raise ValueError("Argument `image_shape` must be provided for NUFFT.")
  image_shape = tf.TensorShape(image_shape)
  image_shape.assert_has_rank(rank)
  if multicoil is None:
    # `multicoil` defaults to True if sensitivities were passed; False
    # otherwise.
    multicoil = sensitivities is not None
  # Compensate non-uniform sampling density.
  if density is None:
    density = traj_ops.estimate_density(trajectory, image_shape)
  kspace = tf.math.divide_no_nan(kspace, tensor_utils.cast_to_complex(density))
  # Do NUFFT.
  image = tfft.nufft(kspace, trajectory,
                     grid_shape=image_shape,
                     transform_type='type_1',
                     fft_direction='backward')
  # Do coil combination.
  if multicoil and combine_coils:
    image = coil_ops.combine_coils(image, maps=sensitivities, coil_axis=-rank-1)
  return image


def _sense(kspace,
           sensitivities,
           reduction_axis,
           reduction_factor,
           rank=None,
           l2_regularizer=0.0,
           fast=True):
  """MR image reconstruction using SENSitivity Encoding (SENSE).

  For the parameters, see `tfmr.reconstruct`.
  """
  # Parse inputs.
  kspace = tf.convert_to_tensor(kspace)
  sensitivities = tf.convert_to_tensor(sensitivities)

  # Rank or spatial dimensionality.
  rank = rank or kspace.shape.rank - 1

  reduced_shape = kspace.shape[-rank:]
  reduction_axis = check_utils.validate_list(
    reduction_axis, element_type=int, name='reduction_axis')
  reduction_factor = check_utils.validate_list(
    reduction_factor, element_type=int, length=len(reduction_axis),
    name='reduction_factor')
  reduction_axis = [ax + rank if ax < 0 else ax for ax in reduction_axis]
  canonical_reduction = [1] * rank
  for ax, r in zip(reduction_axis, reduction_factor):
    canonical_reduction[ax] = r
  image_shape = tf.TensorShape(
    [s * r for s, r in zip(reduced_shape.as_list(), canonical_reduction)])

  # Compute batch shapes. `batch_shape` is the output batch shape.
  kspace_rank = kspace.shape.rank
  kspace_batch_shape = kspace.shape[:-rank-1]
  sens_rank = sensitivities.shape.rank
  sens_batch_shape = sensitivities.shape[:-rank-1]
  batch_shape = tf.broadcast_static_shape(kspace_batch_shape, sens_batch_shape)
  # We do not broadcast the k-space, by design.
  if batch_shape != kspace_batch_shape:
    raise ValueError(
      f"`kspace` and `sensitivities` have incompatible batch shapes: "
      f"{kspace_batch_shape}, {sens_batch_shape}")

  # Rearrange dimensions. Put spatial dimensions first, then coil dimension,
  # then batch dimensions.
  kspace_perm = list(range(-rank, 0)) + [-rank-1]
  kspace_perm = [ax + kspace_rank for ax in kspace_perm]
  kspace_perm += list(range(0, kspace_rank - rank - 1))
  sens_perm = list(range(-rank, 0)) + [-rank-1]
  sens_perm = [ax + sens_rank for ax in sens_perm]
  sens_perm += list(range(0, sens_rank - rank - 1))
  kspace = tf.transpose(kspace, kspace_perm)
  sensitivities = tf.transpose(sensitivities, sens_perm)

  # Compute aliased images and shift along the reduced dimensions.
  aliased_images = fft_ops.ifftn(kspace, axes=list(range(rank)), shift=True)
  aliased_images = tf.signal.ifftshift(aliased_images, axes=reduction_axis)

  # Create a grid of indices into the reduced FOV image.
  reduced_indices = tf.stack(tf.meshgrid(*[tf.range(s) for s in reduced_shape]))
  reduced_indices = tf.transpose(tf.reshape(reduced_indices, [rank, -1]))

  # Compute corresponding indices into the full FOV image.
  offsets = [tf.range(r) * s for s, r in zip(
    reduced_shape.as_list(), canonical_reduction)]
  offsets = tf.transpose(tf.reshape(
    tf.stack(tf.meshgrid(*offsets)), [rank, -1]))
  indices = tf.expand_dims(reduced_indices, -2) + offsets

  # Compute the system matrices, ie, pixel-wise sensitivity matrices folding the
  # full FOV image into a reduced FOV image.
  sens_matrix = tf.gather_nd(sensitivities, indices)
  sens_matrix = tf.transpose(
    sens_matrix, [0, 2, 1] + list(range(3, 3 + sens_batch_shape.rank)))

  # Compute the right hand sides for the set of linear systems.
  rhs = tf.gather_nd(aliased_images, reduced_indices)

  # Remove any pixels known to have zero signal, with no contributions from any
  # of the aliases. Currently we can't do this for batched sensitivities, so it
  # is disabled in that case.
  if sens_batch_shape.rank == 0:
    mask = tf.reduce_sum(tf.math.square(tf.math.abs(sens_matrix)), -2) > 0
    mask = tf.math.reduce_any(mask, axis=-1)
    sens_matrix = tf.boolean_mask(sens_matrix, mask, axis=0)
    rhs = tf.boolean_mask(rhs, mask, axis=0)
    indices = tf.boolean_mask(indices, mask, axis=0)

  # Move batch dimensions to the beginning.
  sens_matrix = tf.transpose(
    sens_matrix, list(range(3, sens_matrix.shape.rank)) + [0, 1, 2])
  rhs = tf.transpose(rhs, list(range(2, rhs.shape.rank)) + [0, 1])
  rhs = tf.expand_dims(rhs, -1)

  # Broadcast the sensitivity matrix as necessary.
  sens_matrix = tf.broadcast_to(
    sens_matrix, batch_shape + sens_matrix.shape[-3:])

  # Solve the pixel-wise linear least-squares problems.
  unfolded_values = tf.linalg.lstsq(sens_matrix, rhs,
                                    l2_regularizer=l2_regularizer,
                                    fast=fast)

  unfolded_values = tf.reshape(unfolded_values, [-1])
  output_indices = tf.reshape(indices, [-1, rank])

  # For batch mode we need to do some additional indexing calculations.
  if batch_shape.rank > 0:
    batch_size = batch_shape.num_elements()
    element_size = unfolded_values.shape[0] // batch_size

    batch_indices = tf.stack(tf.meshgrid(*[tf.range(s) for s in batch_shape]))
    batch_indices = tf.transpose(
      tf.reshape(batch_indices, [batch_shape.rank, -1]))
    batch_indices = tf.expand_dims(batch_indices, -2)
    batch_indices = tf.tile(
      batch_indices, [1] * batch_shape.rank + [element_size, 1])
    batch_indices = tf.reshape(batch_indices, [-1, batch_shape.rank])

    output_indices = tf.tile(output_indices, [batch_size, 1])
    output_indices = tf.concat([batch_indices, output_indices], -1)

  # Scatter the unfolded values into the reconstructed image.
  image = tf.scatter_nd(output_indices, unfolded_values,
                        batch_shape + image_shape)

  return image


def _cg_sense(kspace,
              trajectory,
              density=None,
              sensitivities=None,
              tol=1e-5,
              max_iter=10,
              return_cg_state=False):
  """MR image reconstruction using conjugate gradient SENSE (CG-SENSE).

  For the parameters, see `tfmr.reconstruct`.
  """
  if sensitivities is None:
    raise ValueError("Argument `sensitivities` must be specified for CG-SENSE.")

  # Inputs.
  kspace = tf.convert_to_tensor(kspace)
  sensitivities = tf.convert_to_tensor(sensitivities)
  trajectory = tf.convert_to_tensor(trajectory)

  rank = trajectory.shape[-1]
  num_points = kspace.shape[-1]
  num_coils = kspace.shape[-2]
  batch_shape = kspace.shape[:-2]
  image_shape = sensitivities.shape[-rank:]

  # Check some inputs.
  tf.debugging.assert_equal(
    tf.shape(kspace)[-1], tf.shape(trajectory)[-2], message=(
      f"The number of samples in `kspace` (axis -1) and `trajectory` "
      f"(axis -2) must match, but got: {tf.shape(kspace)[-1]}, "
      f"{tf.shape(trajectory)[-2]}"))
  tf.debugging.assert_equal(
    tf.shape(kspace)[-2], tf.shape(sensitivities)[-rank-1], message=(
      f"The number of coils in `kspace` (axis -2) and `sensitivities` "
      f"(axis {-rank-1}) must match, but got: {tf.shape(kspace)[-1]}, "
      f"{tf.shape(sensitivities)[-rank-1]}"))
  # Check batch shapes.
  kspace_batch_shape = kspace.shape[:-2]
  sens_batch_shape = sensitivities.shape[:-rank-1]
  traj_batch_shape = trajectory.shape[:-2]
  batch_shape = tf.broadcast_static_shape(kspace_batch_shape, sens_batch_shape)
  # We do not broadcast the k-space input, by design.
  if batch_shape != kspace_batch_shape:
    raise ValueError(
      f"`kspace` and `sensitivities` have incompatible batch shapes: "
      f"{kspace_batch_shape}, {sens_batch_shape}")
  batch_shape = tf.broadcast_static_shape(kspace_batch_shape, traj_batch_shape)
  if batch_shape != kspace_batch_shape:
    raise ValueError(
      f"`kspace` and `trajectory` have incompatible batch shapes: "
      f"{kspace_batch_shape}, {traj_batch_shape}")

  # For sampling density correction.
  if density is None:
    # Sampling density not provided, so estimate from trajectory.
    density = traj_ops.estimate_density(trajectory, image_shape)
  else:
    # Use the provided sampling density.
    density = tf.convert_to_tensor(density)
  density = tf.expand_dims(density, -2) # Add coil dimension.

  # For intensity correction.
  intensity = tf.math.reduce_sum(tf.math.square(tf.math.abs(sensitivities)),
                                 axis=-rank-1)

  # Prepare intensity correction linear operator.
  intensity_weights = tf.math.reciprocal_no_nan(intensity)
  linop_intensity = linalg_ops.LinearOperatorRealWeighting(
    tf.math.sqrt(intensity_weights),
    arg_shape=intensity_weights.shape[-rank:],
    dtype=kspace.dtype)

  # Prepare density compensation linear operator.
  density_weights = tf.math.reciprocal_no_nan(density)
  linop_density = linalg_ops.LinearOperatorRealWeighting(
    tf.math.sqrt(density_weights),
    arg_shape=[num_coils, num_points],
    dtype=kspace.dtype)

  # Get non-Cartesian parallel MRI operator.
  linop_parallel_mri = linalg_ops.LinearOperatorParallelMRI(
    sensitivities, trajectory=trajectory)

  # Calculate the right half of the system operator. Then, the left half is the
  # adjoint of the right half.
  linop_right = tf.linalg.LinearOperatorComposition(
    [linop_density, linop_parallel_mri, linop_intensity])
  linop_left = linop_right.H

  # Finally, make system operator. We know this to be self-adjoint and positive
  # definite, as required for CG.
  operator = tf.linalg.LinearOperatorComposition(
    [linop_left, linop_right],
    is_self_adjoint=True, is_positive_definite=True)

  # Step 1. Compute the right hand side of the linear system.
  kspace_vec = tf.reshape(kspace, batch_shape.as_list() + [-1])
  rhs = tf.linalg.matvec(linop_left,
                         tf.linalg.matvec(linop_density, kspace_vec))

  # Step 2. Perform CG iteration to solve modified system.
  result = linalg_ops.conjugate_gradient(operator, rhs,
                                         tol=tol, max_iter=max_iter)

  # Step 3. Correct intensity to obtain solution to original system.
  image_vec = tf.linalg.matvec(linop_intensity, result.x)

  # Restore image shape.
  image = tf.reshape(image_vec, batch_shape.as_list() + image_shape)

  return (image, result) if return_cg_state else image


def _select_reconstruction_method(kspace, # pylint: disable=unused-argument
                                  trajectory,
                                  density,
                                  sensitivities,
                                  method):
  """Select an appropriate reconstruction method based on user inputs.

  For the parameters, see `tfmr.reconstruct`.
  """
  # If user selected a method, use it. We do not check that inputs are valid
  # here, this will be done by the methods themselves.
  if method is not None:
    if method not in _MR_RECON_METHODS:
      return ValueError(
        f"Could not find a reconstruction method named: `{method}`")
    return method

  # No method was specified: choose a default one.
  if sensitivities is None and trajectory is None and density is None:
    return 'fft'

  if sensitivities is None and trajectory is not None:
    return 'nufft'

  if sensitivities is not None and trajectory is None and density is None:
    return 'sense'

  if sensitivities is not None and trajectory is not None:
    return 'cg_sense'

  # Nothing worked.
  raise ValueError(
    "Could not find any reconstruction method that supports the specified "
    "combination of inputs.")


_MR_RECON_METHODS = {
  'fft': _fft,
  'nufft': _nufft,
  'sense': _sense,
  'cg_sense': _cg_sense
}
