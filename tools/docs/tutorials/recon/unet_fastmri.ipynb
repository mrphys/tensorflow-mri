{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a baseline U-Net on the fastMRI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_mri as tfmri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, change the path names here.\n",
    "data_path_train = \"fastmri/brain_multicoil_train\"\n",
    "data_path_val = \"fastmri/brain_multicoil_val\"\n",
    "data_path_test = \"fastmri/brain_multicoil_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train = glob.glob(\"*.h5\", root_dir=data_path_train)\n",
    "files_val = glob.glob(\"*.h5\", root_dir=data_path_val)\n",
    "files_test = glob.glob(\"*.h5\", root_dir=data_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5(filename, spec=None):\n",
    "  \"\"\"Reads an HDF file into a `dict` of `tf.Tensor`s.\n",
    "\n",
    "  Args:\n",
    "    filename: A string, the filename of an HDF5 file.\n",
    "    spec: A dict of `dataset:tf.TensorSpec` or `dataset:dtype`\n",
    "      pairs that specify the HDF5 dataset selected and the `tf.TensorSpec`\n",
    "      or dtype of the dataset. In eager mode the spec is probed\n",
    "      automatically. In graph mode `spec` has to be specified.\n",
    "  \"\"\"\n",
    "  io_tensor = tfio.IOTensor.from_hdf5(filename, spec=spec)\n",
    "  tensors = {k: io_tensor(k).to_tensor() for k in io_tensor.keys}\n",
    "  return {k: tf.ensure_shape(v, spec[k].shape) for k, v in tensors.items()}\n",
    "\n",
    "def create_fastmri_dataset(files,\n",
    "                           element_spec=None,\n",
    "                           batch_size=1,\n",
    "                           shuffle=False):\n",
    "  \"\"\"Creates a `tf.data.Dataset` from a list of fastMRI HDF5 files.\n",
    "  \n",
    "  Args:\n",
    "    files: A list of strings, the filenames of the HDF5 files.\n",
    "    element_spec: The spec of an element of the dataset. See `read_hdf5` for\n",
    "      more details.\n",
    "    batch_size: An int, the batch size.\n",
    "    shuffle: A boolean, whether to shuffle the dataset.\n",
    "  \"\"\"\n",
    "  # Make a `tf.data.Dataset` from the list of files.\n",
    "  ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "  # Read the k-space data from the file.\n",
    "  ds = ds.map(functools.partial(read_hdf5, spec=element_spec))\n",
    "  # The first dimension of the inputs is the slice dimension. Split each\n",
    "  # multi-slice element into multiple single-slice elements, as the\n",
    "  # reconstruction is performed on a slice-by-slice basis.\n",
    "  split_slices = lambda x: tf.data.Dataset.from_tensor_slices(x)\n",
    "  ds = ds.flat_map(split_slices)\n",
    "  # TODO: create mask.\n",
    "\n",
    "  # TODO: create labels.\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "  # Batch the elements.\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_spec = None\n",
    "batch_size = 1\n",
    "\n",
    "ds_train = create_fastmri_dataset(files_train,\n",
    "                                  element_spec=element_spec,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True)\n",
    "\n",
    "ds_val = create_fastmri_dataset(files_val,\n",
    "                                element_spec=element_spec,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "\n",
    "ds_test = create_fastmri_dataset(files_test,\n",
    "                                 element_spec=element_spec,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfmri.models.UNet2D(filters=[32, 64, 128], kernel_size=3)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=[tfmri.metrics.PSNR(),\n",
    "                       tfmri.metrics.SSIM()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds_train, epochs=1, validation_data=ds_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
